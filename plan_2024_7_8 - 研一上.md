# (2024.9-研一上)

## 7.7-7.24 py语法基础

- [x] python基础            --7.17
  
  

## 7.25-10.25 基础课程

### 01.[李宏毅春季机器学习2021/2022](https://www.bilibili.com/video/BV1Wv411h7kN/?vd_source=a357f949bf94bb688228846d79d76428)

#### 第一节 Introduction

* **标题**：深度学习介绍

* **作业**：HW1: Regression

* **学习方法论**：主要是基础概念的介绍，快速过一遍。


#### 第二节 Deep Learning

* **标题**：为什么训练网络会失败

* **作业**：HW2: Classification

* **学习方法论**：主要是将训练网络的一些细节，局部最小值，鞍点，自适应学习率，损失函数等。这一讲的选修的梯度下降必看，新的优化器可以先不看，如果有余力可以看，主要讲了对梯度下降的一些改进。



#### 第三节 Self-Attention

* **标题**：图像与序列输入处理

* **作业**：HW3: CNN, HW4: Self-Attention

* **学习方法论**：图像作为输入，CNN网络，必看，非常重要。



#### 第四节 Theory of ML

* **标题**：机器学习理论

* **作业**：无特定作业提及

* **学习方法论**：**序列作为输入，先看选修的RNN，再去看自注意力机制，不要搞错顺序**。
  因为注意力太火了，所以RNN放在了选修，不过我认为还是要先看RNN模型基础，再去看自注意力机制，为下面的Transformer模型做准备。选修中的GNN网络，可以根据自己的需求，入门阶段可以先跳过不看。



#### 第五节 Transformer

* **标题**：序列到序列的转换

* **作业**：HW5: Transformer

* **学习方法论**：主要讲了Transformer模型，必看。选修的指针网络可以先不看，如有兴趣和时间，可选择性学习。




#### 第六节 Generative Model

* **标题**：生成模型

* **作业**：HW6: GAN

* **学习方法论**：主要是对GAN理论的介绍。根据自己的研究方向，如果是GAN方向的，可以细细看下；如果是入门选手，直接跳过也不影响后续学习。

#### 第七节 Self-Supervised Learning

* **标题**：自监督学习

* **作业**：HW7: BERT, HW8: Autoencoder

* **学习方法论**：必看，很火。主要看关于BERT介绍相关的视频，比如模型介绍、微调、预训练等。BERT的各种变体比如Spanbert等可以先不看，没余力直接跳过，不影响后续学习



### 02.[吴恩达机器学习](https://www.bilibili.com/video/BV1Bq421A74G/)



### 03.[概率论](https://www.bilibili.com/video/BV1WH4y1q7o6/)



### 04.[统计学原理](https://github.com/jonathan-b612/deep-learning/blob/main/statistic_learning/2012-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E7%AC%AC%E4%B8%80%E7%89%88-%E6%9D%8E%E8%88%AA.pdf)



### 05.[李沐论文带读](https://www.bilibili.com/video/BV1H44y1t75x/)



## 9.10-10.20 [code-of-learn-dl-with-pytorch](https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/tree/master)

### 课程目录

#### part1: 深度学习基础

##### Chapter 2: PyTorch基础

- [Tensor和Variable](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter2_PyTorch-Basics/Tensor-and-Variable.ipynb)    
- [自动求导机制](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter2_PyTorch-Basics/autograd.ipynb)
- [动态图与静态图](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter2_PyTorch-Basics/dynamic-graph.ipynb)

##### Chapter 3: 神经网络

- [线性模型与梯度下降](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/linear-regression-gradient-descend.ipynb)

- [Logistic 回归与优化器](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/logistic-regression/logistic-regression.ipynb)

- [多层神经网络，Sequential 和 Module](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/nn-sequential-module.ipynb)

- [深层神经网络](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/deep-nn.ipynb)

- [参数初始化方法](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/param_initialize.ipynb)

- 优化算法
  
  - [SGD](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/sgd.ipynb)
  - [动量法](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/momentum.ipynb)
  - [Adagrad](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/adagrad.ipynb)
  - [RMSProp](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/rmsprop.ipynb)
  - [Adadelta](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/adadelta.ipynb)
  - [Adam](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter3_NN/optimizer/adam.ipynb)

##### Chapter 4: 卷积神经网络

* [PyTorch 中的卷积模块](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/basic_conv.ipynb)
* [批标准化，batch normalization](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/batch-normalization.ipynb)
* [使用重复元素的深度网络，VGG](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/vgg.ipynb)
* [更加丰富化结构的网络，GoogLeNet](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/googlenet.ipynb)
* [深度残差网络，ResNet](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/resnet.ipynb)
* [稠密连接的卷积网络，DenseNet](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/densenet.ipynb)
* 更好的训练卷积网络
  * [数据增强](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/data-augumentation.ipynb)
  * [正则化](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/regularization.ipynb)
  * [学习率衰减](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter4_CNN/lr-decay.ipynb)

##### Chapter 5: 循环神经网络

* [循环神经网络模块：LSTM 和 GRU](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/pytorch-rnn.ipynb)
* [使用 RNN 进行图像分类](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/rnn-for-image.ipynb)
* [使用 RNN 进行时间序列分析](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/lstm-time-series.ipynb)
* 自然语言处理的应用：
  * [Word Embedding](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/nlp/word-embedding.ipynb)
  * [N-Gram 模型](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/nlp/n-gram.ipynb)
  * [Seq-LSTM 做词性预测](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/nlp/seq-lstm.ipynb)

##### Chapter 6: 生成对抗网络

* [自动编码器](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter6_GAN/autoencoder.ipynb)
* [变分自动编码器](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter6_GAN/vae.ipynb)
* [生成对抗网络](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter6_GAN/gan.ipynb)
* 深度卷积对抗网络 (DCGANs) 生成人脸

##### Chapter 7: 深度强化学习

* [Q Learning](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter7_RL/q-learning-intro.ipynb)
* [Open AI gym](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter7_RL/open_ai_gym.ipynb)
* [Deep Q-networks](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter7_RL/dqn.ipynb)

##### Chapter 8: PyTorch高级

* [tensorboard 可视化](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter8_PyTorch-Advances/tensorboard.ipynb)
  * [灵活的数据读取介绍](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter8_PyTorch-Advances/data-io.ipynb)
* autograd.function 的介绍
* 数据并行和多 GPU
* 使用 ONNX 转化为 Caffe2 模型
* 如何部署训练好的神经网络
* 打造属于自己的 PyTorch 的使用习惯

#### part2: 深度学习的应用

##### Chapter 9: 计算机视觉

- [Fine-tuning: 通过微调进行迁移学习](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter9_Computer-Vision/fine_tune/)
- kaggle初体验:猫狗大战
- [语义分割: 通过 FCN 实现像素级别的分类](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/tree/master/chapter9_Computer-Vision/segmentation)
- Pixel to Pixel 生成对抗网络
- Neural Transfer: 通过卷积网络实现风格迁移
- Deep Dream: 探索卷积网络眼中的世界

##### Chapter 10: 自然语言处理

- [Char RNN 实现文本生成](https://github.com/SherlockLiao/code-of-learn-deep-learning-with-pytorch/blob/master/chapter10_Natural-Language-Process/char_rnn/) 
- Image Caption: 实现图片字幕生成
- seq2seq 实现机器翻译
- cnn + rnn + attention 实现文本识别
